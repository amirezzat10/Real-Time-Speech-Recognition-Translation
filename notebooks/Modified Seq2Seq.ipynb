{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPVO95ZxEbp/+QHUQCrvEPv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7lrDLzj5rR7m","executionInfo":{"status":"ok","timestamp":1745585806011,"user_tz":-180,"elapsed":117,"user":{"displayName":"Amir Ezzat","userId":"03584247604066915760"}},"outputId":"8af27c3a-9201-40d6-894c-295755a4ed45"},"outputs":[{"output_type":"stream","name":"stdout","text":["/bin/bash: line 1: nvidia-smi: command not found\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","source":["import os\n","import torch\n","import pandas as pd\n","import numpy as np\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn as nn\n","import torch.optim as optim\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","from torch.utils.checkpoint import checkpoint\n","from torch.nn.utils.rnn import pad_sequence\n","import torch.nn.functional as F"],"metadata":{"id":"9lu-OQ71rW4U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.cuda.is_available()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t1ygXG2Drioi","executionInfo":{"status":"ok","timestamp":1745585812341,"user_tz":-180,"elapsed":32,"user":{"displayName":"Amir Ezzat","userId":"03584247604066915760"}},"outputId":"b60f7a0a-26b9-4604-bf84-7ce68232e944"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QtDm85CHrmKp","executionInfo":{"status":"ok","timestamp":1745583037090,"user_tz":-180,"elapsed":1518,"user":{"displayName":"Amir Ezzat","userId":"03584247604066915760"}},"outputId":"7ba5057c-9903-437f-b3a0-dbf4805d317d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/DEPI_Project"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iPGs-0l8rpco","executionInfo":{"status":"ok","timestamp":1745583037116,"user_tz":-180,"elapsed":8,"user":{"displayName":"Amir Ezzat","userId":"03584247604066915760"}},"outputId":"0b43b08c-bdd6-412b-f034-e520b5f84cd9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/DEPI_Project\n"]}]},{"cell_type":"code","source":["!pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YtVNSSm0rw1C","executionInfo":{"status":"ok","timestamp":1745583037280,"user_tz":-180,"elapsed":163,"user":{"displayName":"Amir Ezzat","userId":"03584247604066915760"}},"outputId":"b8fc9063-9261-47b3-a7b1-4c23fc1e5b3d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/DEPI_Project\n"]}]},{"cell_type":"code","source":["FEATURE_DIR = \"/content/drive/MyDrive/DEPI_Project/featured_extracted/cv-other-dev\"  # Update this\n","CSV_PATH = \"/content/drive/MyDrive/DEPI_Project/mel_processed_dataset.csv\"  # Update this"],"metadata":{"id":"TW6pg7hJr3N3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.cuda.empty_cache()"],"metadata":{"id":"VN67GaPRr5Xo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Config:\n","    \"\"\"Configuration for the audio transcription model\"\"\"\n","    # Data paths\n","    feature_dir = FEATURE_DIR\n","    csv_path = CSV_PATH\n","\n","    # Text processing\n","    vocab = ['<sos>', '<eos>'] + list(\"abcdefghijklmnopqrstuvwxyz' \")\n","    char_to_idx = {char: idx for idx, char in enumerate(vocab)}\n","    idx_to_char = {idx: char for idx, char in enumerate(vocab)}\n","    vocab_size = len(vocab)\n","    sos_idx = char_to_idx['<sos>']\n","    eos_idx = char_to_idx['<eos>']\n","\n","    # Feature dimensions\n","    feature_dim = 128\n","\n","    # Model parameters - better settings for this dataset\n","    hidden_size = 256\n","    num_layers = 2\n","    bidirectional = True\n","    dropout = 0.3  # More reasonable dropout\n","\n","    # Training parameters\n","    batch_size = 16\n","    learning_rate = 0.722081  # Much more reasonable learning rate\n","    weight_decay = 1e-5\n","    num_epochs = 100\n","\n","    # Label smoothing helps with overconfidence\n","    label_smoothing = 0.1\n","\n","    # Curriculum learning parameters\n","    teacher_forcing_ratio_start = 1.0\n","    teacher_forcing_ratio_end = 0.5\n","\n","    # Device\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"yEkXC7G7sAnh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Feature processing fix - Add this function to correctly reshape features\n","def preprocess_features(features, feature_dim):\n","    \"\"\"Properly reshape feature matrices to [time_steps, feature_dim]\"\"\"\n","    # Check dimensions and reshape if needed\n","    if features.shape[0] == features.shape[1] == feature_dim:\n","        # If it's a square matrix, it's likely a misformatted feature\n","        # Let's treat each row as a time step\n","        return features\n","\n","    if len(features.shape) == 2:\n","        if features.shape[1] == feature_dim:\n","            # Already in [time, feature_dim] format\n","            return features\n","        elif features.shape[0] == feature_dim:\n","            # Convert from [feature_dim, time] to [time, feature_dim]\n","            return features.transpose(0, 1)\n","\n","    # If we get a 1D array, reshape to [1, feature_dim]\n","    if len(features.shape) == 1 and features.shape[0] == feature_dim:\n","        return features.reshape(1, -1)\n","\n","    # Return original if we can't determine the correct shape\n","    return features\n"],"metadata":{"id":"ZW3jX89S1whU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class AudioFeatureDataset(Dataset):\n","    def __init__(self, csv_path, config, train=True):\n","        self.config = config\n","        self.train = train\n","\n","        # Load mappings from CSV file\n","        self.df = pd.read_csv(csv_path)\n","\n","        # Ensure feature path column and transcript column exist\n","        if 'feature_path' not in self.df.columns or 'transcript' not in self.df.columns:\n","            raise ValueError(\"CSV file must contain 'feature_path' and 'transcript' columns\")\n","\n","        # Data split\n","        if train:\n","            self.df = self.df.sample(frac=0.8, random_state=42)\n","        else:\n","            all_df = pd.read_csv(csv_path)\n","            train_df = all_df.sample(frac=0.8, random_state=42)\n","            self.df = all_df[~all_df.index.isin(train_df.index)]\n","\n","        # Validate that all feature files exist\n","        valid_rows = []\n","        for idx, row in self.df.iterrows():\n","            feature_path = row['feature_path']\n","            if os.path.exists(feature_path):\n","                valid_rows.append(row)\n","            else:\n","                print(f\"Warning: Feature file not found: {feature_path}\")\n","\n","        if valid_rows:\n","            self.df = pd.DataFrame(valid_rows).reset_index(drop=True)\n","            print(f\"Dataset loaded with {len(self.df)} valid samples\")\n","        else:\n","            raise ValueError(\"No valid feature files found. Check your feature paths in the CSV file.\")\n","\n","    def augment_features(self, features):\n","        \"\"\"Simple augmentation techniques for audio features\"\"\"\n","        if self.train and np.random.random() < 0.7:\n","            # Time masking\n","            if np.random.random() < 0.5:\n","                time_mask_size = max(1, int(features.shape[0] * 0.05))\n","                start = np.random.randint(0, max(1, features.shape[0] - time_mask_size))\n","                features[start:start+time_mask_size, :] = 0\n","\n","            # Feature masking\n","            if np.random.random() < 0.5:\n","                freq_mask_size = max(1, int(features.shape[1] * 0.05))\n","                start = np.random.randint(0, max(1, features.shape[1] - freq_mask_size))\n","                features[:, start:start+freq_mask_size] = 0\n","\n","            # Slight Gaussian noise\n","            if np.random.random() < 0.5:\n","                noise = torch.randn_like(features) * 0.01\n","                features = features + noise\n","\n","        return features\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    # Modify the AudioFeatureDataset.__getitem__ method to use the preprocessing function\n","    def __getitem__(self, idx):\n","        feature_path = self.df.iloc[idx]['feature_path']\n","        transcript = str(self.df.iloc[idx]['transcript']).lower()\n","\n","        # Load features with proper checks\n","        features = np.load(feature_path)\n","        features = torch.tensor(features, dtype=torch.float32)\n","\n","        # Use the new preprocessing function\n","        features = preprocess_features(features, self.config.feature_dim)\n","\n","        # Apply augmentation\n","        features = self.augment_features(features)\n","\n","        # Process transcript - Correct indentation here\n","        text_indices = [self.config.sos_idx] + [self.config.char_to_idx[c] for c in transcript if c in self.config.char_to_idx] + [self.config.eos_idx]\n","        text_indices = torch.tensor(text_indices, dtype=torch.long)\n","\n","        return features, text_indices, features.shape[0], len(text_indices)"],"metadata":{"id":"Zy6WSrtA1yMM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def collate_fn(batch):\n","    batch.sort(key=lambda x: x[2], reverse=True)\n","    features, text_indices, feature_lengths, text_lengths = zip(*batch)\n","\n","    features_padded = pad_sequence(features, batch_first=True)\n","    text_padded = pad_sequence(text_indices, batch_first=True)\n","\n","    feature_lengths = torch.tensor(feature_lengths)\n","    text_lengths = torch.tensor(text_lengths)\n","\n","    return features_padded, text_padded, feature_lengths, text_lengths\n"],"metadata":{"id":"jKBJDuAP10bz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class AudioEncoder(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, num_layers, bidirectional, dropout):\n","        super(AudioEncoder, self).__init__()\n","\n","        # Input normalization\n","        self.layer_norm = nn.LayerNorm(input_dim)\n","        self.batch_norm = nn.BatchNorm1d(input_dim)\n","\n","        self.lstm = nn.LSTM(\n","            input_size=input_dim,\n","            hidden_size=hidden_dim,\n","            num_layers=num_layers,\n","            bidirectional=bidirectional,\n","            dropout=dropout if num_layers > 1 else 0,\n","            batch_first=True\n","        )\n","\n","        self.output_dim = hidden_dim * 2 if bidirectional else hidden_dim\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        for p in self.parameters():\n","            if p.dim() > 1:\n","                nn.init.xavier_uniform_(p)\n","\n","    def forward(self, x, lengths):\n","        # Apply layer normalization\n","        x = self.layer_norm(x)\n","\n","        # Apply batch normalization along feature dimension\n","        batch_size, time_steps, feature_dim = x.size()\n","        x_reshaped = x.reshape(-1, feature_dim)\n","        x_normalized = self.batch_norm(x_reshaped)\n","        x = x_normalized.reshape(batch_size, time_steps, feature_dim)\n","\n","        packed = nn.utils.rnn.pack_padded_sequence(\n","            x, lengths, batch_first=True, enforce_sorted=True\n","        )\n","\n","        # Use gradient checkpointing to save memory\n","        def create_custom_forward(module):\n","            def custom_forward(*inputs):\n","                outputs = module(*inputs)\n","                return outputs\n","            return custom_forward\n","\n","        outputs, _ = checkpoint(create_custom_forward(self.lstm), packed, use_reentrant=False)\n","        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs, batch_first=True)\n","\n","        return outputs\n"],"metadata":{"id":"R5SMdn7412By"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Attention(nn.Module):\n","    def __init__(self, encoder_dim, decoder_dim):\n","        super(Attention, self).__init__()\n","        self.encoder_attn = nn.Linear(encoder_dim, decoder_dim)\n","        self.decoder_attn = nn.Linear(decoder_dim, decoder_dim)\n","        self.full_attn = nn.Linear(decoder_dim, 1)\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        for p in self.parameters():\n","            if p.dim() > 1:\n","                nn.init.xavier_uniform_(p)\n","\n","    def forward(self, decoder_hidden, encoder_outputs):\n","        # Ensure decoder_hidden is properly shaped\n","        if len(decoder_hidden.shape) == 1:\n","            decoder_hidden = decoder_hidden.unsqueeze(0)\n","\n","        # Transform encoder outputs [batch_size, seq_len, encoder_dim] -> [batch_size, seq_len, decoder_dim]\n","        encoder_transform = self.encoder_attn(encoder_outputs)\n","\n","        # Transform decoder hidden [batch_size, decoder_dim] -> [batch_size, 1, decoder_dim]\n","        decoder_transform = self.decoder_attn(decoder_hidden).unsqueeze(1)\n","\n","        # Calculate attention scores with better numerical stability\n","        attn_scores = self.full_attn(torch.tanh(encoder_transform + decoder_transform))\n","\n","        # Get attention weights through softmax with temperature for sharper focus\n","        attn_weights = torch.softmax(attn_scores / 0.5, dim=1)\n","\n","        # Use weights to get context vector [batch_size, 1, encoder_dim]\n","        context = torch.bmm(attn_weights.transpose(1, 2), encoder_outputs)\n","\n","        # Return context with consistent shape [batch_size, encoder_dim]\n","        return context.squeeze(1), attn_weights\n"],"metadata":{"id":"U-xSss2y14Cj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class DecoderRNN(nn.Module):\n","    def __init__(self, vocab_size, hidden_dim, encoder_dim, num_layers, dropout):\n","        super(DecoderRNN, self).__init__()\n","\n","        self.embedding = nn.Embedding(vocab_size, hidden_dim)\n","        self.lstm = nn.LSTM(\n","            input_size=hidden_dim + encoder_dim,\n","            hidden_size=hidden_dim,\n","            num_layers=num_layers,\n","            dropout=dropout if num_layers > 1 else 0,\n","            batch_first=True\n","        )\n","        self.attention = Attention(encoder_dim, hidden_dim)\n","\n","        # Add a projection layer with dropout for better generalization\n","        self.dropout = nn.Dropout(dropout)\n","        self.output_projection = nn.Sequential(\n","            nn.Linear(hidden_dim + encoder_dim, hidden_dim),\n","            nn.GELU(),\n","            nn.Dropout(dropout),\n","            nn.Linear(hidden_dim, vocab_size)\n","        )\n","\n","        self.hidden_dim = hidden_dim\n","        self.encoder_dim = encoder_dim\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        for p in self.parameters():\n","            if p.dim() > 1:\n","                nn.init.xavier_uniform_(p)\n","\n","    def forward_step(self, decoder_input, decoder_hidden, encoder_outputs):\n","        # Ensure decoder_input has proper dimensions [batch_size, 1]\n","        if len(decoder_input.shape) == 1:\n","            decoder_input = decoder_input.unsqueeze(1)\n","\n","        # Get embeddings [batch_size, 1, hidden_dim]\n","        embedded = self.embedding(decoder_input)\n","\n","        # Get context vector and attention weights\n","        context, attention_weights = self.attention(decoder_hidden[0][-1], encoder_outputs)\n","\n","        # Ensure context has correct dimensions to match embedded input\n","        # If context is [batch_size, encoder_dim], reshape to [batch_size, 1, encoder_dim]\n","        if len(context.shape) == 2:\n","            context = context.unsqueeze(1)\n","\n","        # Make sure embedded and context have the same number of dimensions\n","        # embedded shape should be [batch_size, 1, hidden_dim]\n","        # context shape should be [batch_size, 1, encoder_dim]\n","\n","        # Concatenate embedded input and context vector along the feature dimension\n","        lstm_input = torch.cat([embedded, context], dim=-1)\n","\n","        # Forward through LSTM\n","        output, hidden = self.lstm(lstm_input, decoder_hidden)\n","\n","        # Apply dropout to the output\n","        output = self.dropout(output)\n","\n","        # Ensure context and output have compatible dimensions for concatenation\n","        if len(context.shape) != len(output.shape):\n","            if len(context.shape) > len(output.shape):\n","                context = context.squeeze(1)\n","            else:\n","                output = output.squeeze(1)\n","\n","        # Concatenate output and context for prediction\n","        output_context = torch.cat([output, context], dim=-1)\n","        output = self.output_projection(output_context)\n","\n","        return output, hidden, attention_weights\n","\n","    def init_hidden(self, batch_size):\n","        device = next(self.parameters()).device\n","        h0 = torch.zeros(self.lstm.num_layers, batch_size, self.hidden_dim).to(device)\n","        c0 = torch.zeros(self.lstm.num_layers, batch_size, self.hidden_dim).to(device)\n","        return (h0, c0)\n"],"metadata":{"id":"PBesqO37153D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Seq2SeqModel(nn.Module):\n","    def __init__(self, config):\n","        super(Seq2SeqModel, self).__init__()\n","\n","        # Add batch normalization for input features\n","        self.batch_norm = nn.BatchNorm1d(config.feature_dim)\n","\n","        self.encoder = AudioEncoder(\n","            input_dim=config.feature_dim,\n","            hidden_dim=config.hidden_size,\n","            num_layers=config.num_layers,\n","            bidirectional=config.bidirectional,\n","            dropout=config.dropout\n","        )\n","\n","        encoder_dim = config.hidden_size * 2 if config.bidirectional else config.hidden_size\n","\n","        # Add an extra projection layer before decoder\n","        self.encoder_projection = nn.Linear(encoder_dim, config.hidden_size)\n","\n","        self.decoder = DecoderRNN(\n","            vocab_size=config.vocab_size,\n","            hidden_dim=config.hidden_size,\n","            encoder_dim=encoder_dim,\n","            num_layers=config.num_layers,\n","            dropout=config.dropout\n","        )\n","\n","        self.config = config\n","\n","    def forward(self, features, target_texts, feature_lengths, text_lengths, teacher_forcing_ratio=0.9):\n","        batch_size = features.size(0)\n","        max_text_length = target_texts.size(1)\n","\n","        # Apply batch normalization along feature dimension\n","        batch_size, time_steps, feature_dim = features.size()\n","        features_reshaped = features.reshape(-1, feature_dim)\n","        features_normalized = self.batch_norm(features_reshaped)\n","        features = features_normalized.reshape(batch_size, time_steps, feature_dim)\n","\n","        encoder_outputs = self.encoder(features, feature_lengths)\n","        decoder_hidden = self.decoder.init_hidden(batch_size)\n","\n","        # Start with SOS token (0)\n","        decoder_input = torch.zeros(batch_size, 1, dtype=torch.long, device=self.config.device)\n","\n","        outputs = torch.zeros(batch_size, max_text_length, self.config.vocab_size, device=self.config.device)\n","\n","        for t in range(max_text_length):\n","            output, decoder_hidden, _ = self.decoder.forward_step(\n","                decoder_input, decoder_hidden, encoder_outputs\n","            )\n","\n","            outputs[:, t:t+1] = output\n","\n","            # Teaching forcing with high ratio for better learning\n","            use_teacher_forcing = torch.rand(1).item() < teacher_forcing_ratio\n","\n","            if use_teacher_forcing and t < max_text_length - 1:\n","                decoder_input = target_texts[:, t:t+1]\n","            else:\n","                _, topi = output.topk(1)\n","                decoder_input = topi.squeeze(-1).detach()\n","\n","        return outputs\n","\n","    def predict(self, features, feature_lengths):\n","        batch_size = features.size(0)\n","        max_text_length = 200  # Increased max length for prediction\n","\n","        # Apply batch normalization\n","        batch_size, time_steps, feature_dim = features.size()\n","        features_reshaped = features.reshape(-1, feature_dim)\n","        features_normalized = self.batch_norm(features_reshaped)\n","        features = features_normalized.reshape(batch_size, time_steps, feature_dim)\n","\n","        encoder_outputs = self.encoder(features, feature_lengths)\n","        decoder_hidden = self.decoder.init_hidden(batch_size)\n","\n","        # Start with SOS token (assuming token 0 is SOS)\n","        decoder_input = torch.full((batch_size, 1), self.config.sos_idx, dtype=torch.long, device=self.config.device) # Fixed: Removed extra indent\n","        predicted_indices = []\n","        attention_weights_list = []\n","\n","        for t in range(max_text_length):\n","            output, decoder_hidden, attention_weights = self.decoder.forward_step(\n","                decoder_input, decoder_hidden, encoder_outputs\n","            )\n","\n","            # Get the most likely next token\n","            topv, topi = output.topk(1)\n","\n","            # Add prediction to list\n","            predicted_index = topi.squeeze().item()\n","            predicted_indices.append(predicted_index)\n","            attention_weights_list.append(attention_weights)\n","\n","            # Stop at EOS token (assume 1 is EOS token)\n","            if predicted_index == self.config.eos_idx:\n","                break\n","\n","            # Use predicted token as next input\n","            decoder_input = topi.detach()\n","\n","        return predicted_indices, attention_weights_list\n"],"metadata":{"id":"xj-gGAbu18oT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def beam_search_decode(model, features, feature_lengths, beam_width=5, max_length=200, config=None ):  # Remove config=None\n","    \"\"\"Decode using beam search for better results\"\"\"\n","    model.eval()\n","    batch_size = features.shape[0]\n","\n","    # Encode input\n","    encoder_outputs = model.encoder(features, feature_lengths)\n","\n","    # Initialize beam search\n","    beams = [{'sequence': [0], 'score': 0.0, 'hidden': model.decoder.init_hidden(batch_size)}]\n","    finished_beams = []\n","\n","    # Beam search loop\n","    for step in range(max_length):\n","        new_beams = []\n","\n","        for beam in beams:\n","            # Get last token from sequence\n","            last_token = torch.tensor([beam['sequence'][-1]], dtype=torch.long, device=features.device)\n","\n","            # Run through decoder\n","            output, hidden, _ = model.decoder.forward_step(\n","                last_token, beam['hidden'], encoder_outputs\n","            )\n","\n","            # Get top k predictions\n","            logits = output[0]\n","            probs = F.log_softmax(logits, dim=-1)\n","            topk_probs, topk_indices = probs.topk(beam_width)\n","\n","            # Create new beams\n","            for i in range(beam_width):\n","                token = topk_indices[i].item()\n","                log_prob = topk_probs[i].item()\n","\n","                new_beam = {\n","                    'sequence': beam['sequence'] + [token],\n","                    'score': beam['score'] + log_prob,\n","                    'hidden': (hidden[0].clone(), hidden[1].clone()),\n","                }\n","\n","                # If token is EOS, add to finished beams\n","                if token == 1:  # Assuming 1 is EOS token\n","                    finished_beams.append(new_beam)\n","                else:\n","                    new_beams.append(new_beam)\n","\n","        # Sort by score and keep top beam_width\n","        new_beams = sorted(new_beams, key=lambda x: x['score'] / len(x['sequence']), reverse=True)\n","        beams = new_beams[:beam_width]\n","\n","        # Early stopping\n","        if not beams or len(finished_beams) >= beam_width:\n","            break\n","\n","    # Return best finished beam or best ongoing beam\n","    if finished_beams:\n","        best_beam = max(finished_beams, key=lambda x: x['score'] / len(x['sequence']))\n","    else:\n","        best_beam = max(beams, key=lambda x: x['score'] / len(x['sequence']))\n","\n","    return best_beam['sequence'][1:]  # Remove SOS token\n","\n"],"metadata":{"id":"Atbt2Y9k1_ez"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train(model, train_loader, criterion, optimizer, device, epoch, config, clip=1.0):\n","    model.train()\n","    total_loss = 0\n","\n","    # Implement curriculum learning - gradually reduce teacher forcing\n","    # Gradually decrease teacher forcing ratio\n","    teacher_forcing_ratio = max(\n","    config.teacher_forcing_ratio_end,\n","    config.teacher_forcing_ratio_start * (0.95 ** epoch)\n","    )\n","\n","    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch}\")\n","\n","    for batch_idx, (features, target_texts, feature_lengths, text_lengths) in enumerate(progress_bar):\n","        # Move data to device\n","        features = features.to(device)\n","        target_texts = target_texts.to(device)\n","\n","        # Zero gradients\n","        optimizer.zero_grad()\n","\n","        # Forward pass\n","        outputs = model(features, target_texts, feature_lengths, text_lengths,\n","                       teacher_forcing_ratio=teacher_forcing_ratio)\n","\n","        # Calculate loss - use masks for variable length sequences\n","        mask = torch.zeros_like(target_texts, dtype=torch.bool)\n","        for i, length in enumerate(text_lengths):\n","            mask[i, :length] = 1\n","\n","        # Reshape outputs and targets for loss calculation\n","        outputs = outputs.view(-1, outputs.size(-1))\n","        target_texts = target_texts.view(-1)\n","        mask = mask.view(-1)\n","\n","        # Apply mask\n","        outputs = outputs[mask]\n","        target_texts = target_texts[mask]\n","\n","        # Calculate loss\n","        loss = criterion(outputs, target_texts)\n","\n","        # Backward pass\n","        loss.backward()\n","\n","        # Clip gradients - use lower value to stabilize training\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n","\n","        # Update parameters\n","        optimizer.step()\n","\n","        # Update total loss\n","        total_loss += loss.item()\n","\n","        # Update progress bar\n","        progress_bar.set_postfix({\"loss\": loss.item()})\n","\n","    return total_loss / len(train_loader)"],"metadata":{"id":"JPPlpi6T2CFL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def evaluate(model, eval_loader, criterion, device, config):\n","    model.eval()\n","    total_loss = 0\n","    all_true_texts = []\n","    all_pred_texts = []\n","\n","    with torch.no_grad():\n","        for features, target_texts, feature_lengths, text_lengths in tqdm(eval_loader, desc=\"Evaluating\"):\n","            # Move data to device\n","            features = features.to(device)\n","            target_texts = target_texts.to(device)\n","\n","            # Forward pass\n","            outputs = model(features, target_texts, feature_lengths, text_lengths, teacher_forcing_ratio=0)\n","\n","            # Calculate loss with masking\n","            mask = torch.zeros_like(target_texts, dtype=torch.bool)\n","            for i, length in enumerate(text_lengths):\n","                mask[i, :length] = 1\n","\n","            # Reshape for loss calculation\n","            outputs_flat = outputs.view(-1, outputs.size(-1))\n","            target_texts_flat = target_texts.view(-1)\n","            mask_flat = mask.view(-1)\n","\n","            outputs_masked = outputs_flat[mask_flat]\n","            target_texts_masked = target_texts_flat[mask_flat]\n","\n","            loss = criterion(outputs_masked, target_texts_masked)\n","            total_loss += loss.item()\n","\n","            # Store for later analysis\n","            for i in range(min(5, len(features))):  # Limit to avoid excessive memory usage\n","                # Get actual predictions\n","                _, pred_indices = torch.max(outputs[i], dim=1)\n","                pred_indices = pred_indices.cpu().numpy()\n","\n","                # Convert target tensors to integers before using as dictionary keys\n","                true_indices = target_texts[i][:text_lengths[i]].cpu().numpy()\n","\n","                # Convert to text\n","                pred_text = ''.join([config.idx_to_char[idx] for idx in pred_indices[:text_lengths[i]]])\n","                true_text = ''.join([config.idx_to_char[idx] for idx in true_indices])\n","\n","                all_true_texts.append(true_text)\n","                all_pred_texts.append(pred_text)\n","\n","    # Analyze predictions\n","    if len(all_true_texts) > 0:\n","        analyze_predictions(all_true_texts, all_pred_texts)\n","\n","    return total_loss / len(eval_loader)\n"],"metadata":{"id":"KPZyeesK2EHD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def analyze_predictions(true_texts, pred_texts):\n","    \"\"\"Analyze model predictions for common errors\"\"\"\n","    print(\"\\nPrediction Analysis:\")\n","\n","    # Character accuracy\n","    total_chars = 0\n","    correct_chars = 0\n","\n","    # Word accuracy (treat space as separator)\n","    total_words = 0\n","    correct_words = 0\n","\n","    # Common errors\n","    error_patterns = {}\n","\n","    for true, pred in zip(true_texts, pred_texts):\n","        # Character-level analysis\n","        min_len = min(len(true), len(pred))\n","\n","        for i in range(min_len):\n","            total_chars += 1\n","            if true[i] == pred[i]:\n","                correct_chars += 1\n","            else:\n","                error = (true[i], pred[i])\n","                error_patterns[error] = error_patterns.get(error, 0) + 1\n","\n","        # Word-level analysis\n","        true_words = true.strip().split()\n","        pred_words = pred.strip().split()\n","\n","        for i in range(min(len(true_words), len(pred_words))):\n","            total_words += 1\n","            if true_words[i] == pred_words[i]:\n","                correct_words += 1\n","\n","    # Print detailed stats\n","    if total_chars > 0:\n","        char_acc = correct_chars / total_chars * 100\n","        print(f\"Character Accuracy: {char_acc:.2f}%\")\n","\n","    if total_words > 0:\n","        word_acc = correct_words / total_words * 100\n","        print(f\"Word Accuracy: {word_acc:.2f}%\")\n","\n","    # Top errors\n","    top_errors = sorted(error_patterns.items(), key=lambda x: x[1], reverse=True)[:10]\n","    if top_errors:\n","        print(\"Top substitution errors (true → pred):\")\n","        for (true_char, pred_char), count in top_errors:\n","            print(f\"  '{true_char}' → '{pred_char}': {count} times\")\n","\n","    # Print example predictions\n","    print(\"\\nExample predictions:\")\n","    for i in range(min(5, len(true_texts))):\n","        print(f\"True: \\\"{true_texts[i]}\\\"\")\n","        print(f\"Pred: \\\"{pred_texts[i]}\\\"\")\n","        print(\"-\" * 50)"],"metadata":{"id":"wVEWTtoM2GXK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def transcribe(model, feature_path, config):\n","    \"\"\"Transcribe using pre-extracted features from a file\"\"\"\n","    model.eval()\n","\n","    # Load pre-extracted features\n","    features = np.load(feature_path)\n","    features = torch.tensor(features, dtype=torch.float32)\n","\n","    # Handle different feature shapes\n","    # Check dimensions and reshape if needed\n","    if features.shape[0] == features.shape[1] == config.feature_dim:\n","        # Most likely the features are incorrectly shaped\n","        # Reshape to something more sensible for audio (time, features)\n","        features = features.reshape(-1, config.feature_dim)\n","\n","    # Ensure features are [time, feature_dim]\n","    if len(features.shape) == 2:\n","        if features.shape[1] == config.feature_dim:\n","            # Already in [time, feature_dim] format\n","            pass\n","        elif features.shape[0] == config.feature_dim:\n","            # Convert from [feature_dim, time] to [time, feature_dim]\n","            features = features.transpose(0, 1)\n","        else:\n","            raise ValueError(f\"Unexpected feature shape: {features.shape}\")\n","    else:\n","        raise ValueError(f\"Unexpected feature shape: {features.shape}\")\n","\n","    # Prepare for model\n","    feature_length = features.shape[0]\n","    features = features.unsqueeze(0).to(config.device)  # Add batch dimension\n","\n","    with torch.no_grad():\n","        # Use beam search for better results\n","        predicted_indices = beam_search_decode(model, features, torch.tensor([feature_length]), beam_width=5, config=config) # Fixed: Indented this line\n","\n","    # Convert indices to text\n","    transcription = \"\".join([config.idx_to_char.get(idx, \"\") for idx in predicted_indices])\n","\n","    return transcription\n"],"metadata":{"id":"JpkSQRX22Ir7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def early_stopping(val_losses, patience=10):\n","    \"\"\"\n","    Check if training should stop early based on validation loss plateau\n","    Returns True if training should stop, False otherwise\n","    \"\"\"\n","    # Need at least patience+1 epochs of validation data\n","    if len(val_losses) <= patience:\n","        return False\n","\n","    # Check if validation loss hasn't improved for the last 'patience' epochs\n","    best_loss_idx = val_losses.index(min(val_losses))\n","    return len(val_losses) - best_loss_idx > patience\n"],"metadata":{"id":"Ng1GGsrK2L2D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_and_use_model(model_path, feature_path, config=None):\n","    \"\"\"Load a trained model and use it to transcribe audio\"\"\"\n","    # Load the saved model\n","    checkpoint = torch.load(model_path)\n","\n","    if config is None:\n","        # Create a config from the saved parameters\n","        config = Config()\n","        config.feature_dim = checkpoint['config']['feature_dim']\n","        config.hidden_size = checkpoint['config']['hidden_size']\n","        config.num_layers = checkpoint['config']['num_layers']\n","        config.bidirectional = checkpoint['config']['bidirectional']\n","        config.dropout = checkpoint['config']['dropout']\n","        config.vocab_size = checkpoint['config']['vocab_size']\n","        config.char_to_idx = checkpoint['config']['char_to_idx']\n","        config.idx_to_char = checkpoint['config']['idx_to_char']\n","\n","    # Initialize model\n","    model = Seq2SeqModel(config).to(config.device)\n","\n","    # Load weights\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","\n","    # Set to evaluation mode\n","    model.eval()\n","\n","    # Transcribe\n","    transcription, _ = transcribe(model, feature_path, config)\n","\n","    return transcription"],"metadata":{"id":"iLpX3kwe2NtK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def find_learning_rate(model, train_loader, criterion, device, start_lr=1e-7, end_lr=1, num_steps=100):\n","    \"\"\"Find optimal learning rate by exponentially increasing it\"\"\"\n","    model.train()\n","\n","    # Create log-spaced learning rates\n","    lrs = np.logspace(np.log10(start_lr), np.log10(end_lr), num_steps)\n","    losses = []\n","\n","    # Initialize optimizer with small learning rate\n","    optimizer = optim.AdamW(model.parameters(), lr=start_lr)\n","\n","    # Store original model state\n","    original_state = {k: v.clone() for k, v in model.state_dict().items()}\n","\n","    # Get a batch of data\n","    data_iter = iter(train_loader)\n","\n","    # Iterate through learning rates\n","    for i, lr in enumerate(tqdm(lrs, desc=\"Finding optimal learning rate\")):\n","        # Update learning rate\n","        for param_group in optimizer.param_groups:\n","            param_group['lr'] = lr\n","\n","        try:\n","            # Try to get a batch, if we run out, reset the iterator\n","            try:\n","                features, target_texts, feature_lengths, text_lengths = next(data_iter)\n","            except StopIteration:\n","                data_iter = iter(train_loader)\n","                features, target_texts, feature_lengths, text_lengths = next(data_iter)\n","\n","            features = features.to(device)\n","            target_texts = target_texts.to(device)\n","\n","            # Zero gradients\n","            optimizer.zero_grad()\n","\n","            # Forward pass\n","            outputs = model(features, target_texts, feature_lengths, text_lengths)\n","\n","            # Calculate loss with masking\n","            mask = torch.zeros_like(target_texts, dtype=torch.bool)\n","            for j, length in enumerate(text_lengths):\n","                mask[j, :length] = 1\n","\n","            # Reshape for loss calculation\n","            outputs_flat = outputs.view(-1, outputs.size(-1))\n","            target_texts_flat = target_texts.view(-1)\n","            mask_flat = mask.view(-1)\n","\n","            outputs_masked = outputs_flat[mask_flat]\n","            target_texts_masked = target_texts_flat[mask_flat]\n","\n","            loss = criterion(outputs_masked, target_texts_masked)\n","\n","            # Backward pass\n","            loss.backward()\n","\n","            # Store loss\n","            current_loss = loss.item()\n","            losses.append(current_loss)\n","\n","            # If loss explodes, stop\n","            if len(losses) > 1 and current_loss > 4 * losses[-2]:\n","                print(f\"Loss exploded from {losses[-2]} to {current_loss} at learning rate {lr}. Stopping.\")\n","                break\n","\n","        except Exception as e:\n","            print(f\"Error occurred at learning rate {lr}: {e}\")\n","            break\n","\n","    # Restore original model state\n","    model.load_state_dict(original_state)\n","\n","    # If we didn't collect any losses, return a default value\n","    if not losses:\n","        print(\"Could not determine optimal learning rate. Using default value.\")\n","        return 1e-3\n","\n","    # Plot results if we have enough data points\n","    if len(losses) > 1:\n","        plt.figure(figsize=(10, 6))\n","        plt.plot(lrs[:len(losses)], losses)\n","        plt.xscale('log')\n","        plt.xlabel('Learning Rate')\n","        plt.ylabel('Loss')\n","        plt.title('Learning Rate Finder')\n","        plt.savefig('learning_rate_finder.png')\n","\n","        # Find optimal learning rate (where loss drops the fastest)\n","        try:\n","            derivative = np.gradient(losses)\n","            optimal_idx = np.argmin(derivative)\n","            optimal_lr = lrs[optimal_idx]\n","            print(f\"Suggested learning rate: {optimal_lr:.6f}\")\n","            return optimal_lr\n","        except:\n","            # Fall back to a more robust method if gradient calculation fails\n","            min_loss_idx = np.argmin(losses)\n","            if min_loss_idx > 0:\n","                optimal_lr = lrs[min_loss_idx] / 10  # Conservative choice\n","                print(f\"Falling back to conservative learning rate: {optimal_lr:.6f}\")\n","                return optimal_lr\n","\n","    # If all else fails, return a reasonable default\n","    print(\"Using default learning rate\")\n","    return 1e-3"],"metadata":{"id":"uSLFxuod2QIy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Modify the main function to address the model loading issue\n","def main():\n","    # Initialize config\n","    config = Config()\n","\n","    # Create datasets and dataloaders\n","    train_dataset = AudioFeatureDataset(\n","        csv_path=config.csv_path,\n","        config=config,\n","        train=True\n","    )\n","\n","    val_dataset = AudioFeatureDataset(\n","        csv_path=config.csv_path,\n","        config=config,\n","        train=False\n","    )\n","\n","    # Before creating DataLoader, print a few samples' feature shape\n","    print(f\"Expected feature dimension: {config.feature_dim}\")\n","\n","    # Sample a few entries to verify dimensions\n","    for i in range(5):\n","        features, _, _, _ = train_dataset[i]\n","        print(f\"Sample {i} feature shape: {features.shape}\")\n","\n","    train_loader = DataLoader(\n","        train_dataset,\n","        batch_size=config.batch_size,\n","        shuffle=True,\n","        collate_fn=collate_fn,\n","        num_workers=2,\n","        pin_memory=True\n","    )\n","\n","    val_loader = DataLoader(\n","        val_dataset,\n","        batch_size=config.batch_size,\n","        shuffle=False,\n","        collate_fn=collate_fn,\n","        num_workers=2,\n","        pin_memory=True\n","    )\n","\n","    # Print dataset statistics\n","    print(f\"Training samples: {len(train_dataset)}\")\n","    print(f\"Validation samples: {len(val_dataset)}\")\n","\n","    # Skip the learning rate finder - use a reasonable default instead\n","    config.learning_rate = 0.001\n","\n","    # Initialize model\n","    model = Seq2SeqModel(config).to(config.device)\n","    print(f\"Model initialized on {config.device}\")\n","\n","    # Loss and optimizer with label smoothing\n","    criterion = nn.CrossEntropyLoss(label_smoothing=config.label_smoothing)\n","    optimizer = optim.AdamW(\n","        model.parameters(),\n","        lr=config.learning_rate,\n","        weight_decay=config.weight_decay\n","    )\n","\n","    # Learning rate scheduler with warmup and plateau reduction\n","    from torch.optim.lr_scheduler import ReduceLROnPlateau\n","    scheduler = ReduceLROnPlateau(\n","        optimizer,\n","        mode='min',\n","        factor=0.5,\n","        patience=5,\n","        verbose=True\n","    )\n","\n","    # Training loop\n","    best_val_loss = float('inf')\n","    train_losses = []\n","    val_losses = []\n","    no_improvement_count = 0\n","    early_stop_patience = 15  # More patience for early stopping\n","\n","    for epoch in range(1, config.num_epochs + 1):\n","        # Train\n","        train_loss = train(model, train_loader, criterion, optimizer, config.device, epoch, config)\n","        train_losses.append(train_loss)\n","\n","        # Evaluate\n","        val_loss = evaluate(model, val_loader, criterion, config.device, config)\n","        val_losses.append(val_loss)\n","\n","        # Update learning rate scheduler\n","        scheduler.step(val_loss)\n","\n","        print(f\"Epoch {epoch}: Train Loss = {train_loss:.4f}, Val Loss = {val_loss:.4f}\")\n","\n","        # Check if this is the best model so far\n","        if val_loss < best_val_loss:\n","            best_val_loss = val_loss\n","            no_improvement_count = 0\n","            torch.save({\n","                'epoch': epoch,\n","                'model_state_dict': model.state_dict(),\n","                'optimizer_state_dict': optimizer.state_dict(),\n","                'train_loss': train_loss,\n","                'val_loss': val_loss,\n","                'config': {\n","                    'feature_dim': config.feature_dim,\n","                    'hidden_size': config.hidden_size,\n","                    'num_layers': config.num_layers,\n","                    'bidirectional': config.bidirectional,\n","                    'dropout': config.dropout,\n","                    'vocab_size': config.vocab_size,\n","                    'char_to_idx': config.char_to_idx,\n","                    'idx_to_char': config.idx_to_char\n","                }\n","            }, 'best_audio_transcription_model.pth')\n","            print(\"Saved new best model!\")\n","        else:\n","            no_improvement_count += 1\n","            print(f\"No improvement for {no_improvement_count} epochs\")\n","\n","        # Early stopping check\n","        if no_improvement_count >= early_stop_patience:\n","            print(f\"Early stopping triggered after {epoch} epochs (no improvement for {early_stop_patience} epochs)\")\n","            break\n","\n","    # Plot training history\n","    plt.figure(figsize=(10, 5))\n","    plt.plot(train_losses, label='Training Loss')\n","    plt.plot(val_losses, label='Validation Loss')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.title('Training and Validation Loss')\n","    plt.savefig('training_history.png')\n","    plt.show()\n","\n","    # Load the best model for testing with weights_only=False\n","    print(\"\\nLoading best model for testing...\")\n","    try:\n","        checkpoint = torch.load('best_audio_transcription_model.pth', weights_only=False)\n","        model.load_state_dict(checkpoint['model_state_dict'])\n","\n","        # Test the model on a few samples\n","        print(\"\\nTesting model on a few examples:\")\n","        for i in range(min(5, len(val_dataset))):\n","            feature_path = val_dataset.df.iloc[i]['feature_path']\n","            true_transcription = val_dataset.df.iloc[i]['transcript']\n","\n","            pred_transcription = transcribe(model, feature_path, config)\n","\n","            print(f\"\\nSample {i+1}: {os.path.basename(feature_path)}\")\n","            print(f\"True: {true_transcription}\")\n","            print(f\"Pred: {pred_transcription}\")\n","    except Exception as e:\n","        print(f\"Error loading model: {e}\")\n","        print(\"Continuing with the current model state without loading checkpoint...\")\n","\n","        # Test with the current model state\n","        print(\"\\nTesting current model on a few examples:\")\n","        for i in range(min(5, len(val_dataset))):\n","            feature_path = val_dataset.df.iloc[i]['feature_path']\n","            true_transcription = val_dataset.df.iloc[i]['transcript']\n","\n","            pred_transcription = transcribe(model, feature_path, config)\n","\n","            print(f\"\\nSample {i+1}: {os.path.basename(feature_path)}\")\n","            print(f\"True: {true_transcription}\")\n","            print(f\"Pred: {pred_transcription}\")"],"metadata":{"id":"iL4RhPYP2THi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V26Oml1h2WjK","outputId":"ac981687-7fbb-43c6-a8a0-da32534f4815"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset loaded with 2404 valid samples\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Dataset loaded with 601 valid samples\n","Expected feature dimension: 128\n","Sample 0 feature shape: torch.Size([128, 128])\n","Sample 1 feature shape: torch.Size([128, 128])\n","Sample 2 feature shape: torch.Size([128, 128])\n","Sample 3 feature shape: torch.Size([128, 128])\n","Sample 4 feature shape: torch.Size([128, 128])\n","Training samples: 2404\n","Validation samples: 601\n","Model initialized on cuda\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1: 100%|██████████| 151/151 [16:34<00:00,  6.59s/it, loss=2.58]\n","Evaluating: 100%|██████████| 38/38 [04:41<00:00,  7.41s/it]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Prediction Analysis:\n","Character Accuracy: 20.73%\n","Word Accuracy: 6.15%\n","Top substitution errors (true → pred):\n","  ' ' → 't': 339 times\n","  ' ' → 'h': 291 times\n","  ' ' → 'e': 284 times\n","  'e' → 'h': 206 times\n","  'e' → 't': 185 times\n","  'e' → ' ': 178 times\n","  't' → ' ': 154 times\n","  't' → 'h': 141 times\n","  'a' → 't': 140 times\n","  'o' → ' ': 130 times\n","\n","Example predictions:\n","True: \"<sos>i could die happily and that made me feel good<eos>\"\n","Pred: \"<sos>the the the the the the the the the the the the\"\n","--------------------------------------------------\n","True: \"<sos>are you going to live with your mother<eos>\"\n","Pred: \"<sos>the cout the the the the the the the th\"\n","--------------------------------------------------\n","True: \"<sos>the waitress was carrying an impressive amount of dinnerware but then an earthquake occurred and she dropped it all<eos>\"\n","Pred: \"<sos>the sout the the the the the the the the the the the the the the the the the the the the the the the the the the the\"\n","--------------------------------------------------\n","True: \"<sos>how old are you<eos>\"\n","Pred: \"<sos>the cout the the\"\n","--------------------------------------------------\n","True: \"<sos>i was impatient to see it opened<eos>\"\n","Pred: \"<sos>the to the the the the the the th\"\n","--------------------------------------------------\n","Epoch 1: Train Loss = 2.7657, Val Loss = 3.5043\n","Saved new best model!\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2: 100%|██████████| 151/151 [00:54<00:00,  2.78it/s, loss=2.47]\n","Evaluating: 100%|██████████| 38/38 [00:04<00:00,  8.58it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Prediction Analysis:\n","Character Accuracy: 18.90%\n","Word Accuracy: 3.56%\n","Top substitution errors (true → pred):\n","  ' ' → 'e': 246 times\n","  'e' → ' ': 169 times\n","  ' ' → 't': 164 times\n","  ' ' → 'h': 142 times\n","  't' → ' ': 142 times\n","  ' ' → 's': 134 times\n","  'h' → ' ': 131 times\n","  'o' → ' ': 131 times\n","  'e' → 't': 114 times\n","  't' → 'e': 110 times\n","\n","Example predictions:\n","True: \"<sos>i could die happily and that made me feel good<eos>\"\n","Pred: \"<sos>i don't the sare the sare the boy the boy the b\"\n","--------------------------------------------------\n","True: \"<sos>are you going to live with your mother<eos>\"\n","Pred: \"<sos>i was the sare the boy the boy the boy \"\n","--------------------------------------------------\n","True: \"<sos>the waitress was carrying an impressive amount of dinnerware but then an earthquake occurred and she dropped it all<eos>\"\n","Pred: \"<sos>i don't the sare the sare the sare the boy the boy the boy the boy the boy the boy the boy the boy the boy the boy t\"\n","--------------------------------------------------\n","True: \"<sos>how old are you<eos>\"\n","Pred: \"<sos>i was the sant t\"\n","--------------------------------------------------\n","True: \"<sos>i was impatient to see it opened<eos>\"\n","Pred: \"<sos>i was the sant the boy the boy th\"\n","--------------------------------------------------\n","Epoch 2: Train Loss = 2.4607, Val Loss = 3.5421\n","No improvement for 1 epochs\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3: 100%|██████████| 151/151 [00:52<00:00,  2.88it/s, loss=2.24]\n","Evaluating: 100%|██████████| 38/38 [00:04<00:00,  7.60it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Prediction Analysis:\n","Character Accuracy: 18.71%\n","Word Accuracy: 3.69%\n","Top substitution errors (true → pred):\n","  ' ' → 'e': 222 times\n","  'e' → ' ': 211 times\n","  ' ' → 't': 179 times\n","  ' ' → 'h': 173 times\n","  't' → ' ': 147 times\n","  'o' → ' ': 144 times\n","  'a' → ' ': 136 times\n","  'h' → ' ': 123 times\n","  ' ' → 'b': 117 times\n","  'n' → ' ': 101 times\n","\n","Example predictions:\n","True: \"<sos>i could die happily and that made me feel good<eos>\"\n","Pred: \"<sos>i was the see the boy the boy the boy the boy t\"\n","--------------------------------------------------\n","True: \"<sos>are you going to live with your mother<eos>\"\n","Pred: \"<sos>i was the see the boy the boy the boy t\"\n","--------------------------------------------------\n","True: \"<sos>the waitress was carrying an impressive amount of dinnerware but then an earthquake occurred and she dropped it all<eos>\"\n","Pred: \"<sos>i was the see the boy the boy the boy the boy the boy the boy the boy the boy the boy the boy the boy the boy the bo\"\n","--------------------------------------------------\n","True: \"<sos>how old are you<eos>\"\n","Pred: \"<sos>i was the see th\"\n","--------------------------------------------------\n","True: \"<sos>i was impatient to see it opened<eos>\"\n","Pred: \"<sos>i was the see the boy the boy the\"\n","--------------------------------------------------\n","Epoch 3: Train Loss = 2.3919, Val Loss = 3.6141\n","No improvement for 2 epochs\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4: 100%|██████████| 151/151 [00:53<00:00,  2.83it/s, loss=2.3]\n","Evaluating: 100%|██████████| 38/38 [00:04<00:00,  7.82it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Prediction Analysis:\n","Character Accuracy: 19.15%\n","Word Accuracy: 3.71%\n","Top substitution errors (true → pred):\n","  'e' → ' ': 195 times\n","  ' ' → 't': 151 times\n","  ' ' → 'e': 148 times\n","  ' ' → 'i': 135 times\n","  ' ' → 'h': 133 times\n","  ' ' → 'd': 128 times\n","  'o' → ' ': 123 times\n","  ' ' → 'a': 117 times\n","  ' ' → 's': 108 times\n","  'a' → ' ': 107 times\n","\n","Example predictions:\n","True: \"<sos>i could die happily and that made me feel good<eos>\"\n","Pred: \"<sos>the said the said the said the said the said th\"\n","--------------------------------------------------\n","True: \"<sos>are you going to live with your mother<eos>\"\n","Pred: \"<sos>i don't to the said the boy to the boy<eos>\"\n","--------------------------------------------------\n","True: \"<sos>the waitress was carrying an impressive amount of dinnerware but then an earthquake occurred and she dropped it all<eos>\"\n","Pred: \"<sos>the said the said the said the said the said the said the said the said the said the said the said the said the said\"\n","--------------------------------------------------\n","True: \"<sos>how old are you<eos>\"\n","Pred: \"<sos>i don't to the s\"\n","--------------------------------------------------\n","True: \"<sos>i was impatient to see it opened<eos>\"\n","Pred: \"<sos>the said the said the boy to the \"\n","--------------------------------------------------\n","Epoch 4: Train Loss = 2.3908, Val Loss = 3.5275\n","No improvement for 3 epochs\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5: 100%|██████████| 151/151 [00:54<00:00,  2.79it/s, loss=2.15]\n","Evaluating: 100%|██████████| 38/38 [00:04<00:00,  8.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Prediction Analysis:\n","Character Accuracy: 18.49%\n","Word Accuracy: 3.89%\n","Top substitution errors (true → pred):\n","  'e' → ' ': 219 times\n","  'h' → ' ': 151 times\n","  't' → ' ': 150 times\n","  ' ' → 't': 143 times\n","  ' ' → 'e': 139 times\n","  ' ' → 'h': 138 times\n","  'o' → ' ': 135 times\n","  ' ' → 'o': 131 times\n","  'a' → ' ': 130 times\n","  ' ' → 'b': 109 times\n","\n","Example predictions:\n","True: \"<sos>i could die happily and that made me feel good<eos>\"\n","Pred: \"<sos>i was the boy a sear the boy the boy the boy th\"\n","--------------------------------------------------\n","True: \"<sos>are you going to live with your mother<eos>\"\n","Pred: \"<sos>i was the boy to the boy to the boy<eos><eos>an\"\n","--------------------------------------------------\n","True: \"<sos>the waitress was carrying an impressive amount of dinnerware but then an earthquake occurred and she dropped it all<eos>\"\n","Pred: \"<sos>i was a could the boy a sear the boy the boy the boy the boy the boy the boy the boy the boy the boy the boy the boy\"\n","--------------------------------------------------\n","True: \"<sos>how old are you<eos>\"\n","Pred: \"<sos>i was the boy to\"\n","--------------------------------------------------\n","True: \"<sos>i was impatient to see it opened<eos>\"\n","Pred: \"<sos>i was the boy the boy the boy the\"\n","--------------------------------------------------\n","Epoch 5: Train Loss = 2.3811, Val Loss = 3.4706\n","Saved new best model!\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6: 100%|██████████| 151/151 [00:53<00:00,  2.81it/s, loss=2.49]\n","Evaluating: 100%|██████████| 38/38 [00:05<00:00,  7.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Prediction Analysis:\n","Character Accuracy: 19.71%\n","Word Accuracy: 4.02%\n","Top substitution errors (true → pred):\n","  ' ' → 't': 177 times\n","  'e' → ' ': 169 times\n","  ' ' → 'e': 152 times\n","  ' ' → 'h': 145 times\n","  't' → ' ': 145 times\n","  ' ' → 'o': 117 times\n","  'e' → 'o': 107 times\n","  'o' → ' ': 106 times\n","  'a' → ' ': 101 times\n","  's' → ' ': 101 times\n","\n","Example predictions:\n","True: \"<sos>i could die happily and that made me feel good<eos>\"\n","Pred: \"<sos>the boy to the boy the boy the boy the said<eos>the\"\n","--------------------------------------------------\n","True: \"<sos>are you going to live with your mother<eos>\"\n","Pred: \"<sos>the boy to the boy to the boy<eos><eos><eos>at<eos><eos><eos>th\"\n","--------------------------------------------------\n","True: \"<sos>the waitress was carrying an impressive amount of dinnerware but then an earthquake occurred and she dropped it all<eos>\"\n","Pred: \"<sos>the boy the said the boy the boy the said the boy the said<eos>the boy the said<eos>the boy the said<eos>the boy the said<eos>the bo\"\n","--------------------------------------------------\n","True: \"<sos>how old are you<eos>\"\n","Pred: \"<sos>the boy to the b\"\n","--------------------------------------------------\n","True: \"<sos>i was impatient to see it opened<eos>\"\n","Pred: \"<sos>the boy to the boy to the boy to \"\n","--------------------------------------------------\n","Epoch 6: Train Loss = 2.4005, Val Loss = 3.3455\n","Saved new best model!\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 7: 100%|██████████| 151/151 [00:53<00:00,  2.81it/s, loss=2.09]\n","Evaluating: 100%|██████████| 38/38 [00:04<00:00,  8.43it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Prediction Analysis:\n","Character Accuracy: 18.99%\n","Word Accuracy: 4.41%\n","Top substitution errors (true → pred):\n","  'e' → ' ': 183 times\n","  ' ' → 'e': 176 times\n","  'o' → ' ': 140 times\n","  ' ' → 'h': 135 times\n","  ' ' → 'a': 128 times\n","  ' ' → 't': 126 times\n","  't' → ' ': 118 times\n","  'a' → ' ': 110 times\n","  'h' → ' ': 109 times\n","  'e' → 't': 99 times\n","\n","Example predictions:\n","True: \"<sos>i could die happily and that made me feel good<eos>\"\n","Pred: \"<sos>the e the said the boy and the said the boy tan\"\n","--------------------------------------------------\n","True: \"<sos>are you going to live with your mother<eos>\"\n","Pred: \"<sos>i was the boy to the boy the boy<eos><eos>one<eos>t\"\n","--------------------------------------------------\n","True: \"<sos>the waitress was carrying an impressive amount of dinnerware but then an earthquake occurred and she dropped it all<eos>\"\n","Pred: \"<sos>the e the said the boy and the boy and the said<eos>the sare the said<eos>the sare the said<eos>the sare the said<eos>the sare the s\"\n","--------------------------------------------------\n","True: \"<sos>how old are you<eos>\"\n","Pred: \"<sos>i was the boy th\"\n","--------------------------------------------------\n","True: \"<sos>i was impatient to see it opened<eos>\"\n","Pred: \"<sos>i was the boy the boy the said<eos>th\"\n","--------------------------------------------------\n","Epoch 7: Train Loss = 2.4394, Val Loss = 3.3030\n","Saved new best model!\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 8: 100%|██████████| 151/151 [00:53<00:00,  2.80it/s, loss=2.21]\n","Evaluating: 100%|██████████| 38/38 [00:05<00:00,  7.01it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Prediction Analysis:\n","Character Accuracy: 20.36%\n","Word Accuracy: 3.97%\n","Top substitution errors (true → pred):\n","  'e' → ' ': 258 times\n","  ' ' → 't': 244 times\n","  ' ' → 'e': 169 times\n","  't' → ' ': 168 times\n","  'a' → ' ': 160 times\n","  'o' → ' ': 155 times\n","  ' ' → 'o': 150 times\n","  'e' → 't': 149 times\n","  'i' → ' ': 129 times\n","  'h' → ' ': 128 times\n","\n","Example predictions:\n","True: \"<sos>i could die happily and that made me feel good<eos>\"\n","Pred: \"<sos>the  out the  out the  out the  out the  out th\"\n","--------------------------------------------------\n","True: \"<sos>are you going to live with your mother<eos>\"\n","Pred: \"<sos>the  out the  out the  out the boy took\"\n","--------------------------------------------------\n","True: \"<sos>the waitress was carrying an impressive amount of dinnerware but then an earthquake occurred and she dropped it all<eos>\"\n","Pred: \"<sos>the  out the  out the  out the  out the  out the  out the  out the boy and to the tor the sere to the tor the sere t\"\n","--------------------------------------------------\n","True: \"<sos>how old are you<eos>\"\n","Pred: \"<sos>i was the  out t\"\n","--------------------------------------------------\n","True: \"<sos>i was impatient to see it opened<eos>\"\n","Pred: \"<sos>the boy was the boy to the boy to\"\n","--------------------------------------------------\n","Epoch 8: Train Loss = 2.4582, Val Loss = 3.1767\n","Saved new best model!\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 9: 100%|██████████| 151/151 [00:54<00:00,  2.77it/s, loss=2.38]\n","Evaluating: 100%|██████████| 38/38 [00:04<00:00,  8.60it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Prediction Analysis:\n","Character Accuracy: 20.54%\n","Word Accuracy: 3.77%\n","Top substitution errors (true → pred):\n","  'e' → ' ': 220 times\n","  ' ' → 'e': 176 times\n","  't' → ' ': 172 times\n","  ' ' → 'o': 164 times\n","  ' ' → 't': 159 times\n","  ' ' → 'h': 136 times\n","  'a' → ' ': 129 times\n","  'e' → 'o': 128 times\n","  'o' → ' ': 124 times\n","  'i' → ' ': 114 times\n","\n","Example predictions:\n","True: \"<sos>i could die happily and that made me feel good<eos>\"\n","Pred: \"<sos>the boy a see the said the boy the said the boy\"\n","--------------------------------------------------\n","True: \"<sos>are you going to live with your mother<eos>\"\n","Pred: \"<sos>the boy the  out the boy to the boy<eos><eos>on\"\n","--------------------------------------------------\n","True: \"<sos>the waitress was carrying an impressive amount of dinnerware but then an earthquake occurred and she dropped it all<eos>\"\n","Pred: \"<sos>the boy a see the  on the boy the boy the boy the boy the boy the boy the boy the said<eos>the boy the said<eos>the boy the \"\n","--------------------------------------------------\n","True: \"<sos>how old are you<eos>\"\n","Pred: \"<sos>i don't tant to \"\n","--------------------------------------------------\n","True: \"<sos>i was impatient to see it opened<eos>\"\n","Pred: \"<sos>the boy a se the boy the boy to t\"\n","--------------------------------------------------\n","Epoch 9: Train Loss = 2.4845, Val Loss = 3.3001\n","No improvement for 1 epochs\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 10: 100%|██████████| 151/151 [00:53<00:00,  2.83it/s, loss=2.41]\n","Evaluating: 100%|██████████| 38/38 [00:05<00:00,  6.99it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Prediction Analysis:\n","Character Accuracy: 20.81%\n","Word Accuracy: 4.22%\n","Top substitution errors (true → pred):\n","  'e' → ' ': 202 times\n","  't' → ' ': 176 times\n","  ' ' → 'e': 163 times\n","  'o' → ' ': 131 times\n","  ' ' → 'o': 121 times\n","  'a' → ' ': 120 times\n","  ' ' → 'a': 113 times\n","  ' ' → 't': 110 times\n","  'r' → ' ': 106 times\n","  'h' → ' ': 102 times\n","\n","Example predictions:\n","True: \"<sos>i could die happily and that made me feel good<eos>\"\n","Pred: \"<sos>the boy was a see the boy and the boy and the b\"\n","--------------------------------------------------\n","True: \"<sos>are you going to live with your mother<eos>\"\n","Pred: \"<sos>ihe boy a see  on the boy took<eos>the boy<eos>\"\n","--------------------------------------------------\n","True: \"<sos>the waitress was carrying an impressive amount of dinnerware but then an earthquake occurred and she dropped it all<eos>\"\n","Pred: \"<sos>the boy was a see  the boy and the boy and the boy and the boy and the boy and the boy and the boy and the boy and t\"\n","--------------------------------------------------\n","True: \"<sos>how old are you<eos>\"\n","Pred: \"<sos>ihe boy a see  a\"\n","--------------------------------------------------\n","True: \"<sos>i was impatient to see it opened<eos>\"\n","Pred: \"<sos>ihe boy was the boy and the boy t\"\n","--------------------------------------------------\n","Epoch 10: Train Loss = 2.5275, Val Loss = 3.2462\n","No improvement for 2 epochs\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 11: 100%|██████████| 151/151 [00:53<00:00,  2.81it/s, loss=2.56]\n","Evaluating: 100%|██████████| 38/38 [00:04<00:00,  8.68it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Prediction Analysis:\n","Character Accuracy: 21.62%\n","Word Accuracy: 4.16%\n","Top substitution errors (true → pred):\n","  'e' → ' ': 309 times\n","  't' → ' ': 241 times\n","  'a' → ' ': 208 times\n","  'o' → ' ': 197 times\n","  'h' → ' ': 164 times\n","  ' ' → 'e': 158 times\n","  ' ' → 'o': 155 times\n","  'i' → ' ': 153 times\n","  'r' → ' ': 149 times\n","  'n' → ' ': 147 times\n","\n","Example predictions:\n","True: \"<sos>i could die happily and that made me feel good<eos>\"\n","Pred: \"<sos>the  oy a s the  ore   the  ore   the  ore  the\"\n","--------------------------------------------------\n","True: \"<sos>are you going to live with your mother<eos>\"\n","Pred: \"<sos>i was  the  ore  on the boy to the boy<eos>\"\n","--------------------------------------------------\n","True: \"<sos>the waitress was carrying an impressive amount of dinnerware but then an earthquake occurred and she dropped it all<eos>\"\n","Pred: \"<sos>the  oo   a   the  ore   the  ore  to the boy and the boy and the boy and the boy and the boy and the boy and the bo\"\n","--------------------------------------------------\n","True: \"<sos>how old are you<eos>\"\n","Pred: \"<sos>i was  the  ore \"\n","--------------------------------------------------\n","True: \"<sos>i was impatient to see it opened<eos>\"\n","Pred: \"<sos>the  oo   a   to  e t to the boy \"\n","--------------------------------------------------\n","Epoch 11: Train Loss = 2.5515, Val Loss = 3.1463\n","Saved new best model!\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 12: 100%|██████████| 151/151 [00:53<00:00,  2.81it/s, loss=2.37]\n","Evaluating: 100%|██████████| 38/38 [00:05<00:00,  7.60it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Prediction Analysis:\n","Character Accuracy: 23.91%\n","Word Accuracy: 4.27%\n","Top substitution errors (true → pred):\n","  'e' → ' ': 511 times\n","  't' → ' ': 388 times\n","  'a' → ' ': 325 times\n","  'o' → ' ': 293 times\n","  's' → ' ': 252 times\n","  'i' → ' ': 249 times\n","  'n' → ' ': 241 times\n","  'h' → ' ': 233 times\n","  'r' → ' ': 226 times\n","  'l' → ' ': 147 times\n","\n","Example predictions:\n","True: \"<sos>i could die happily and that made me feel good<eos>\"\n","Pred: \"<sos>the  ee      a   the  e     the  e    the  e   \"\n","--------------------------------------------------\n","True: \"<sos>are you going to live with your mother<eos>\"\n","Pred: \"<sos>i  an       t to   the  e t to   a   th\"\n","--------------------------------------------------\n","True: \"<sos>the waitress was carrying an impressive amount of dinnerware but then an earthquake occurred and she dropped it all<eos>\"\n","Pred: \"<sos>the  oo   a    a    the  e    a   the  e    a   the  ee    a   the  ee    a   the  ee    a   the  ee    a   the  ee \"\n","--------------------------------------------------\n","True: \"<sos>how old are you<eos>\"\n","Pred: \"<sos>i   a         a \"\n","--------------------------------------------------\n","True: \"<sos>i was impatient to see it opened<eos>\"\n","Pred: \"<sos>the  oo       a    the  e     the\"\n","--------------------------------------------------\n","Epoch 12: Train Loss = 2.5625, Val Loss = 3.0244\n","Saved new best model!\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 13: 100%|██████████| 151/151 [00:54<00:00,  2.78it/s, loss=2.77]\n","Evaluating: 100%|██████████| 38/38 [00:04<00:00,  8.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Prediction Analysis:\n","Character Accuracy: 23.09%\n","Word Accuracy: 3.86%\n","Top substitution errors (true → pred):\n","  'e' → ' ': 443 times\n","  't' → ' ': 318 times\n","  'a' → ' ': 285 times\n","  'o' → ' ': 252 times\n","  'r' → ' ': 217 times\n","  'i' → ' ': 216 times\n","  'h' → ' ': 216 times\n","  's' → ' ': 216 times\n","  'n' → ' ': 199 times\n","  'd' → ' ': 131 times\n","\n","Example predictions:\n","True: \"<sos>i could die happily and that made me feel good<eos>\"\n","Pred: \"<sos>the  e          the  an    the  o the  o the  o\"\n","--------------------------------------------------\n","True: \"<sos>are you going to live with your mother<eos>\"\n","Pred: \"<sos>i           t the  oon <eos>o the  oon<eos><eos><eos><eos><eos>\"\n","--------------------------------------------------\n","True: \"<sos>the waitress was carrying an impressive amount of dinnerware but then an earthquake occurred and she dropped it all<eos>\"\n","Pred: \"<sos>the  o             a   the  an   a   the  an   a   the  an  an  e the  an  an  e the  an  an  e the  an  an  e the  \"\n","--------------------------------------------------\n","True: \"<sos>how old are you<eos>\"\n","Pred: \"<sos>i           the \"\n","--------------------------------------------------\n","True: \"<sos>i was impatient to see it opened<eos>\"\n","Pred: \"<sos>i wan         the  o the  on the \"\n","--------------------------------------------------\n","Epoch 13: Train Loss = 2.5942, Val Loss = 3.0492\n","No improvement for 1 epochs\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 14: 100%|██████████| 151/151 [00:53<00:00,  2.83it/s, loss=2.46]\n","Evaluating: 100%|██████████| 38/38 [00:04<00:00,  8.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Prediction Analysis:\n","Character Accuracy: 25.01%\n","Word Accuracy: 3.25%\n","Top substitution errors (true → pred):\n","  'e' → ' ': 554 times\n","  't' → ' ': 431 times\n","  'a' → ' ': 347 times\n","  'o' → ' ': 334 times\n","  'n' → ' ': 273 times\n","  'i' → ' ': 272 times\n","  's' → ' ': 272 times\n","  'h' → ' ': 258 times\n","  'r' → ' ': 258 times\n","  'l' → ' ': 160 times\n","\n","Example predictions:\n","True: \"<sos>i could die happily and that made me feel good<eos>\"\n","Pred: \"<sos>the  oo                e  o  the  or        the\"\n","--------------------------------------------------\n","True: \"<sos>are you going to live with your mother<eos>\"\n","Pred: \"<sos>ihe  oo               e  oo  oo  oo the\"\n","--------------------------------------------------\n","True: \"<sos>the waitress was carrying an impressive amount of dinnerware but then an earthquake occurred and she dropped it all<eos>\"\n","Pred: \"<sos>the  oo                                     the  or         the  or       the  or       the  or      the  or    the \"\n","--------------------------------------------------\n","True: \"<sos>how old are you<eos>\"\n","Pred: \"<sos>ihe  oo         \"\n","--------------------------------------------------\n","True: \"<sos>i was impatient to see it opened<eos>\"\n","Pred: \"<sos>the  oo                      the \"\n","--------------------------------------------------\n","Epoch 14: Train Loss = 2.6043, Val Loss = 2.9883\n","Saved new best model!\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 15: 100%|██████████| 151/151 [00:53<00:00,  2.82it/s, loss=2.62]\n","Evaluating: 100%|██████████| 38/38 [00:05<00:00,  7.03it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Prediction Analysis:\n","Character Accuracy: 23.28%\n","Word Accuracy: 4.61%\n","Top substitution errors (true → pred):\n","  'e' → ' ': 498 times\n","  't' → ' ': 356 times\n","  'a' → ' ': 292 times\n","  'o' → ' ': 262 times\n","  'h' → ' ': 227 times\n","  's' → ' ': 225 times\n","  'i' → ' ': 222 times\n","  'n' → ' ': 222 times\n","  'r' → ' ': 218 times\n","  'd' → ' ': 131 times\n","\n","Example predictions:\n","True: \"<sos>i could die happily and that made me feel good<eos>\"\n","Pred: \"<sos>the  is a   t the  at  a   the  at the  ore  an\"\n","--------------------------------------------------\n","True: \"<sos>are you going to live with your mother<eos>\"\n","Pred: \"<sos>i   a            t to   the  oy toe <eos>oo\"\n","--------------------------------------------------\n","True: \"<sos>the waitress was carrying an impressive amount of dinnerware but then an earthquake occurred and she dropped it all<eos>\"\n","Pred: \"<sos>the  are  an   a   t the  are  an   an   an  an  and the  are the  are the  are the  are the  are the  are the  are \"\n","--------------------------------------------------\n","True: \"<sos>how old are you<eos>\"\n","Pred: \"<sos>i   a        the\"\n","--------------------------------------------------\n","True: \"<sos>i was impatient to see it opened<eos>\"\n","Pred: \"<sos>the  oo           a   the  oo  an\"\n","--------------------------------------------------\n","Epoch 15: Train Loss = 2.5955, Val Loss = 3.0038\n","No improvement for 1 epochs\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 16: 100%|██████████| 151/151 [00:53<00:00,  2.81it/s, loss=2.54]\n","Evaluating: 100%|██████████| 38/38 [00:04<00:00,  8.57it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Prediction Analysis:\n","Character Accuracy: 24.84%\n","Word Accuracy: 4.37%\n","Top substitution errors (true → pred):\n","  'e' → ' ': 619 times\n","  't' → ' ': 452 times\n","  'a' → ' ': 380 times\n","  'o' → ' ': 340 times\n","  's' → ' ': 300 times\n","  'h' → ' ': 294 times\n","  'i' → ' ': 286 times\n","  'n' → ' ': 282 times\n","  'r' → ' ': 275 times\n","  'l' → ' ': 169 times\n","\n","Example predictions:\n","True: \"<sos>i could die happily and that made me feel good<eos>\"\n","Pred: \"<sos>the e the  an                   the  o the  oe \"\n","--------------------------------------------------\n","True: \"<sos>are you going to live with your mother<eos>\"\n","Pred: \"<sos>i                        t to the e<eos>ter\"\n","--------------------------------------------------\n","True: \"<sos>the waitress was carrying an impressive amount of dinnerware but then an earthquake occurred and she dropped it all<eos>\"\n","Pred: \"<sos>the e the  an                                   the  an  e  on  the  on  the  on  the  on  the  on  the  on  the  on\"\n","--------------------------------------------------\n","True: \"<sos>how old are you<eos>\"\n","Pred: \"<sos>ihe  o          \"\n","--------------------------------------------------\n","True: \"<sos>i was impatient to see it opened<eos>\"\n","Pred: \"<sos>the  oo                     the  \"\n","--------------------------------------------------\n","Epoch 16: Train Loss = 2.5941, Val Loss = 2.9843\n","Saved new best model!\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 17: 100%|██████████| 151/151 [00:54<00:00,  2.80it/s, loss=2.57]\n","Evaluating: 100%|██████████| 38/38 [00:05<00:00,  6.92it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Prediction Analysis:\n","Character Accuracy: 22.99%\n","Word Accuracy: 3.19%\n","Top substitution errors (true → pred):\n","  'e' → ' ': 431 times\n","  't' → ' ': 329 times\n","  'a' → ' ': 277 times\n","  'o' → ' ': 264 times\n","  'h' → ' ': 229 times\n","  'n' → ' ': 212 times\n","  'i' → ' ': 209 times\n","  's' → ' ': 208 times\n","  'r' → ' ': 198 times\n","  ' ' → 'o': 144 times\n","\n","Example predictions:\n","True: \"<sos>i could die happily and that made me feel good<eos>\"\n","Pred: \"<sos>the boy s a   the  oo      the  oo  and the boy\"\n","--------------------------------------------------\n","True: \"<sos>are you going to live with your mother<eos>\"\n","Pred: \"<sos>ihe  oo            the  ooe<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\"\n","--------------------------------------------------\n","True: \"<sos>the waitress was carrying an impressive amount of dinnerware but then an earthquake occurred and she dropped it all<eos>\"\n","Pred: \"<sos>the  oan             a   the  oan      the  oan      the  oan  o  e  o  e  o  e  on  o  e  on  and the  oane  o  e  \"\n","--------------------------------------------------\n","True: \"<sos>how old are you<eos>\"\n","Pred: \"<sos>ihe  oo         \"\n","--------------------------------------------------\n","True: \"<sos>i was impatient to see it opened<eos>\"\n","Pred: \"<sos>the  oo                 the  oo  \"\n","--------------------------------------------------\n","Epoch 17: Train Loss = 2.5742, Val Loss = 3.0781\n","No improvement for 1 epochs\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 18: 100%|██████████| 151/151 [00:53<00:00,  2.82it/s, loss=2.65]\n","Evaluating: 100%|██████████| 38/38 [00:04<00:00,  8.46it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Prediction Analysis:\n","Character Accuracy: 24.03%\n","Word Accuracy: 4.10%\n","Top substitution errors (true → pred):\n","  'e' → ' ': 473 times\n","  't' → ' ': 377 times\n","  'a' → ' ': 307 times\n","  'o' → ' ': 259 times\n","  'i' → ' ': 250 times\n","  'r' → ' ': 248 times\n","  's' → ' ': 229 times\n","  'h' → ' ': 225 times\n","  'n' → ' ': 213 times\n","  'd' → ' ': 146 times\n","\n","Example predictions:\n","True: \"<sos>i could die happily and that made me feel good<eos>\"\n","Pred: \"<sos>the boy a s a                   the  ore  the  \"\n","--------------------------------------------------\n","True: \"<sos>are you going to live with your mother<eos>\"\n","Pred: \"<sos>i e  a                the  ore the  ore\"\n","--------------------------------------------------\n","True: \"<sos>the waitress was carrying an impressive amount of dinnerware but then an earthquake occurred and she dropped it all<eos>\"\n","Pred: \"<sos>the  are  a              the  are the  an  an  the  are the  an  an  the  are the  an  an  the  are the  an  an  the\"\n","--------------------------------------------------\n","True: \"<sos>how old are you<eos>\"\n","Pred: \"<sos>i was see  the  \"\n","--------------------------------------------------\n","True: \"<sos>i was impatient to see it opened<eos>\"\n","Pred: \"<sos>the boy was a   t t the  or the  \"\n","--------------------------------------------------\n","Epoch 18: Train Loss = 2.5720, Val Loss = 3.0349\n","No improvement for 2 epochs\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 19: 100%|██████████| 151/151 [00:52<00:00,  2.88it/s, loss=2.83]\n","Evaluating: 100%|██████████| 38/38 [00:04<00:00,  8.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Prediction Analysis:\n","Character Accuracy: 24.10%\n","Word Accuracy: 4.58%\n","Top substitution errors (true → pred):\n","  'e' → ' ': 508 times\n","  't' → ' ': 387 times\n","  'a' → ' ': 315 times\n","  'o' → ' ': 296 times\n","  'i' → ' ': 267 times\n","  'h' → ' ': 260 times\n","  's' → ' ': 248 times\n","  'n' → ' ': 236 times\n","  'r' → ' ': 232 times\n","  'd' → ' ': 147 times\n","\n","Example predictions:\n","True: \"<sos>i could die happily and that made me feel good<eos>\"\n","Pred: \"<sos>i  as                                          \"\n","--------------------------------------------------\n","True: \"<sos>are you going to live with your mother<eos>\"\n","Pred: \"<sos>i e  oo               e  oo  e  one<eos><eos><eos><eos>\"\n","--------------------------------------------------\n","True: \"<sos>the waitress was carrying an impressive amount of dinnerware but then an earthquake occurred and she dropped it all<eos>\"\n","Pred: \"<sos>the  are  a   a   a   a   a   a   the  an  an  an  an  an  an  an  an  an  an  an  an  an  an  an  an  an  an  an  a\"\n","--------------------------------------------------\n","True: \"<sos>how old are you<eos>\"\n","Pred: \"<sos>i don't know wha\"\n","--------------------------------------------------\n","True: \"<sos>i was impatient to see it opened<eos>\"\n","Pred: \"<sos>the  oo                   the  or\"\n","--------------------------------------------------\n","Epoch 19: Train Loss = 2.5642, Val Loss = 3.0758\n","No improvement for 3 epochs\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 20: 100%|██████████| 151/151 [00:54<00:00,  2.78it/s, loss=2.49]\n","Evaluating: 100%|██████████| 38/38 [00:04<00:00,  7.71it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Prediction Analysis:\n","Character Accuracy: 23.53%\n","Word Accuracy: 2.86%\n","Top substitution errors (true → pred):\n","  'e' → ' ': 492 times\n","  't' → ' ': 370 times\n","  'a' → ' ': 302 times\n","  'o' → ' ': 267 times\n","  'n' → ' ': 241 times\n","  'i' → ' ': 227 times\n","  'r' → ' ': 224 times\n","  's' → ' ': 222 times\n","  'h' → ' ': 210 times\n","  ' ' → 'e': 183 times\n","\n","Example predictions:\n","True: \"<sos>i could die happily and that made me feel good<eos>\"\n","Pred: \"<sos>the  oe                    the  ear    the  ore\"\n","--------------------------------------------------\n","True: \"<sos>are you going to live with your mother<eos>\"\n","Pred: \"<sos>ihe  oo             e  o  e  o  e e<eos><eos>er\"\n","--------------------------------------------------\n","True: \"<sos>the waitress was carrying an impressive amount of dinnerware but then an earthquake occurred and she dropped it all<eos>\"\n","Pred: \"<sos>the e was a e the  are  an  the  are  an  the  are the  are the  are the  are the  are the  are the  are the  are th\"\n","--------------------------------------------------\n","True: \"<sos>how old are you<eos>\"\n","Pred: \"<sos>the  oo         \"\n","--------------------------------------------------\n","True: \"<sos>i was impatient to see it opened<eos>\"\n","Pred: \"<sos>the  oo                   the  or\"\n","--------------------------------------------------\n","Epoch 20: Train Loss = 2.5547, Val Loss = 3.0267\n","No improvement for 4 epochs\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 21: 100%|██████████| 151/151 [00:53<00:00,  2.81it/s, loss=2.64]\n","Evaluating: 100%|██████████| 38/38 [00:04<00:00,  8.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Prediction Analysis:\n","Character Accuracy: 24.94%\n","Word Accuracy: 3.08%\n","Top substitution errors (true → pred):\n","  'e' → ' ': 627 times\n","  't' → ' ': 476 times\n","  'a' → ' ': 392 times\n","  'o' → ' ': 332 times\n","  'n' → ' ': 312 times\n","  'h' → ' ': 301 times\n","  'i' → ' ': 295 times\n","  's' → ' ': 294 times\n","  'r' → ' ': 283 times\n","  'd' → ' ': 176 times\n","\n","Example predictions:\n","True: \"<sos>i could die happily and that made me feel good<eos>\"\n","Pred: \"<sos>the  oo                                        \"\n","--------------------------------------------------\n","True: \"<sos>are you going to live with your mother<eos>\"\n","Pred: \"<sos>i    ou t    e  e            e  ee  e  \"\n","--------------------------------------------------\n","True: \"<sos>the waitress was carrying an impressive amount of dinnerware but then an earthquake occurred and she dropped it all<eos>\"\n","Pred: \"<sos>the  are  a                                        e  an  an  ear  an  an  ear  an  an  ear  an  an  ear  an  an  ea\"\n","--------------------------------------------------\n","True: \"<sos>how old are you<eos>\"\n","Pred: \"<sos>ihe  oo         \"\n","--------------------------------------------------\n","True: \"<sos>i was impatient to see it opened<eos>\"\n","Pred: \"<sos>the  oo                    our  o\"\n","--------------------------------------------------\n","Epoch 21: Train Loss = 2.5695, Val Loss = 2.9830\n","Saved new best model!\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 22: 100%|██████████| 151/151 [00:53<00:00,  2.85it/s, loss=2.5]\n","Evaluating: 100%|██████████| 38/38 [00:05<00:00,  6.89it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Prediction Analysis:\n","Character Accuracy: 22.27%\n","Word Accuracy: 4.24%\n","Top substitution errors (true → pred):\n","  'e' → ' ': 418 times\n","  't' → ' ': 334 times\n","  'o' → ' ': 266 times\n","  'a' → ' ': 261 times\n","  'h' → ' ': 226 times\n","  's' → ' ': 216 times\n","  'i' → ' ': 211 times\n","  'n' → ' ': 209 times\n","  'r' → ' ': 192 times\n","  ' ' → 'e': 128 times\n","\n","Example predictions:\n","True: \"<sos>i could die happily and that made me feel good<eos>\"\n","Pred: \"<sos>i  an  t the  or                             th\"\n","--------------------------------------------------\n","True: \"<sos>are you going to live with your mother<eos>\"\n","Pred: \"<sos>i  as the  oo   a   the boy<eos><eos><eos>an<eos><eos><eos><eos><eos><eos><eos>\"\n","--------------------------------------------------\n","True: \"<sos>the waitress was carrying an impressive amount of dinnerware but then an earthquake occurred and she dropped it all<eos>\"\n","Pred: \"<sos>the  are  a   t the  are  an  the  are  an  the  ore the  ore the  ore the  ore the  ore the  ore the  ore the  ore \"\n","--------------------------------------------------\n","True: \"<sos>how old are you<eos>\"\n","Pred: \"<sos>i  an't know wha\"\n","--------------------------------------------------\n","True: \"<sos>i was impatient to see it opened<eos>\"\n","Pred: \"<sos>i was  o  the  oo   the  oo  the \"\n","--------------------------------------------------\n","Epoch 22: Train Loss = 2.5451, Val Loss = 3.0874\n","No improvement for 1 epochs\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 23: 100%|██████████| 151/151 [00:53<00:00,  2.81it/s, loss=2.7]\n","Evaluating: 100%|██████████| 38/38 [00:04<00:00,  8.55it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Prediction Analysis:\n","Character Accuracy: 23.87%\n","Word Accuracy: 3.12%\n","Top substitution errors (true → pred):\n","  'e' → ' ': 494 times\n","  't' → ' ': 384 times\n","  'a' → ' ': 309 times\n","  'o' → ' ': 280 times\n","  'i' → ' ': 238 times\n","  's' → ' ': 226 times\n","  'n' → ' ': 225 times\n","  'r' → ' ': 223 times\n","  'h' → ' ': 219 times\n","  'l' → ' ': 151 times\n","\n","Example predictions:\n","True: \"<sos>i could die happily and that made me feel good<eos>\"\n","Pred: \"<sos>the  oe   e   the  ore                         \"\n","--------------------------------------------------\n","True: \"<sos>are you going to live with your mother<eos>\"\n","Pred: \"<sos>i  ould  a   to   a   to  e to the  oot\"\n","--------------------------------------------------\n","True: \"<sos>the waitress was carrying an impressive amount of dinnerware but then an earthquake occurred and she dropped it all<eos>\"\n","Pred: \"<sos>the  are a   a   the  are and the  are and the  are the  are the  are the  are the  are the  are the  are the  are t\"\n","--------------------------------------------------\n","True: \"<sos>how old are you<eos>\"\n","Pred: \"<sos>i   not to   a  \"\n","--------------------------------------------------\n","True: \"<sos>i was impatient to see it opened<eos>\"\n","Pred: \"<sos>the  oo           the  or the  or\"\n","--------------------------------------------------\n","Epoch 23: Train Loss = 2.5510, Val Loss = 3.0349\n","No improvement for 2 epochs\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 24: 100%|██████████| 151/151 [00:54<00:00,  2.79it/s, loss=2.42]\n","Evaluating: 100%|██████████| 38/38 [00:05<00:00,  6.88it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Prediction Analysis:\n","Character Accuracy: 24.43%\n","Word Accuracy: 4.28%\n","Top substitution errors (true → pred):\n","  'e' → ' ': 574 times\n","  't' → ' ': 426 times\n","  'a' → ' ': 342 times\n","  'o' → ' ': 319 times\n","  'i' → ' ': 275 times\n","  'r' → ' ': 270 times\n","  's' → ' ': 270 times\n","  'h' → ' ': 262 times\n","  'n' → ' ': 257 times\n","  'd' → ' ': 155 times\n","\n","Example predictions:\n","True: \"<sos>i could die happily and that made me feel good<eos>\"\n","Pred: \"<sos>the  oe                                        \"\n","--------------------------------------------------\n","True: \"<sos>are you going to live with your mother<eos>\"\n","Pred: \"<sos>i                                  to  \"\n","--------------------------------------------------\n","True: \"<sos>the waitress was carrying an impressive amount of dinnerware but then an earthquake occurred and she dropped it all<eos>\"\n","Pred: \"<sos>the e the  e                                          e  e e the  eee the  eeer<eos><eos>n the sand<eos><eos><eos> an  e e the  eeer<eos><eos>n \"\n","--------------------------------------------------\n","True: \"<sos>how old are you<eos>\"\n","Pred: \"<sos>i               \"\n","--------------------------------------------------\n","True: \"<sos>i was impatient to see it opened<eos>\"\n","Pred: \"<sos>the  oo                      o  h\"\n","--------------------------------------------------\n","Epoch 24: Train Loss = 2.5439, Val Loss = 3.0200\n","No improvement for 3 epochs\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 25:  94%|█████████▍| 142/151 [00:50<00:02,  3.04it/s, loss=2.86]"]}]},{"cell_type":"code","source":[],"metadata":{"id":"xWrQU-472X3C"},"execution_count":null,"outputs":[]}]}